{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe463ab8",
   "metadata": {},
   "source": [
    "### Basic Data Cleaning\n",
    "###  How to identify and remove column variables that only have a single value.\n",
    "###  How to identify and consider column variables with very few unique values.\n",
    "###  How to identify and remove rows that contain duplicate observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9f66c7",
   "metadata": {},
   "source": [
    "### Overview\n",
    "### 1. Messy Datasets\n",
    "### 2. Identify Columns That Contain a Single Value\n",
    "### 3. Delete Columns That Contain a Single Value\n",
    "### 4. Consider Columns That Have Very Few Values\n",
    "### 5. Remove Columns That Have A Low Variance\n",
    "### 6. Identify Rows that Contain Duplicate Data\n",
    "### 7. Delete Rows that Contain Duplicate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab3c0f6",
   "metadata": {},
   "source": [
    "### Messy Datasets\n",
    "### Data cleaning refers to identifying and correcting errors in the dataset that may negatively impact a predictive model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2a215",
   "metadata": {},
   "source": [
    "### Identify Columns That Contain a Single Value\n",
    "### Columns that have a single observation or value are probably useless for modeling. These columns or predictors are referred to zero-variance predictors as if we measured the variance (average value from the mean), it would be zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab7e3b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset (936, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2558</th>\n",
       "      <th>1506.09</th>\n",
       "      <th>456.63</th>\n",
       "      <th>90</th>\n",
       "      <th>6395000</th>\n",
       "      <th>40.88</th>\n",
       "      <th>7.89</th>\n",
       "      <th>29780</th>\n",
       "      <th>0.19</th>\n",
       "      <th>...</th>\n",
       "      <th>2850</th>\n",
       "      <th>1000</th>\n",
       "      <th>763.16</th>\n",
       "      <th>135.46</th>\n",
       "      <th>3.73</th>\n",
       "      <th>0.6</th>\n",
       "      <th>33243.19</th>\n",
       "      <th>65.74</th>\n",
       "      <th>7.95</th>\n",
       "      <th>1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>22325</td>\n",
       "      <td>79.11</td>\n",
       "      <td>841.03</td>\n",
       "      <td>180</td>\n",
       "      <td>55812500.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>61900.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>9593.48</td>\n",
       "      <td>1648.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>51572.04</td>\n",
       "      <td>65.73</td>\n",
       "      <td>6.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1449.85</td>\n",
       "      <td>608.43</td>\n",
       "      <td>88</td>\n",
       "      <td>287500.0</td>\n",
       "      <td>40.42</td>\n",
       "      <td>7.34</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>150.00</td>\n",
       "      <td>45.13</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1</td>\n",
       "      <td>31692.84</td>\n",
       "      <td>65.81</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1   2558  1506.09  456.63   90     6395000  40.88  7.89    29780  0.19  \\\n",
       "0  2  22325    79.11  841.03  180  55812500.0  51.11  1.21  61900.0  0.02   \n",
       "1  3    115  1449.85  608.43   88    287500.0  40.42  7.34   3340.0  0.18   \n",
       "\n",
       "   ...    2850     1000   763.16   135.46  3.73  0.6  33243.19  65.74  7.95  \\\n",
       "0  ...  5750.0  11500.0  9593.48  1648.80  0.60    0  51572.04  65.73  6.26   \n",
       "1  ...  1400.0    250.0   150.00    45.13  9.33    1  31692.84  65.81  7.84   \n",
       "\n",
       "   1.1  \n",
       "0    0  \n",
       "1    1  \n",
       "\n",
       "[2 rows x 50 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('oil-spill.csv')\n",
    "print('Shape of dataset', data.shape)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30109535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 238\n",
      "1 297\n",
      "2 927\n",
      "3 933\n",
      "4 179\n",
      "5 375\n",
      "6 820\n",
      "7 618\n",
      "8 561\n",
      "9 57\n",
      "10 577\n",
      "11 59\n",
      "12 73\n",
      "13 107\n",
      "14 53\n",
      "15 91\n",
      "16 893\n",
      "17 810\n",
      "18 170\n",
      "19 53\n",
      "20 68\n",
      "21 9\n",
      "22 1\n",
      "23 92\n",
      "24 9\n",
      "25 8\n",
      "26 9\n",
      "27 308\n",
      "28 447\n",
      "29 392\n",
      "30 107\n",
      "31 42\n",
      "32 4\n",
      "33 45\n",
      "34 141\n",
      "35 110\n",
      "36 3\n",
      "37 758\n",
      "38 9\n",
      "39 9\n",
      "40 388\n",
      "41 220\n",
      "42 644\n",
      "43 649\n",
      "44 499\n",
      "45 2\n",
      "46 937\n",
      "47 169\n",
      "48 286\n",
      "49 2\n"
     ]
    }
   ],
   "source": [
    "# summarize the number of unique values for each column using numpy\n",
    "from numpy import loadtxt\n",
    "from numpy import unique\n",
    "# load the dataset\n",
    "data = loadtxt('oil-spill.csv', delimiter=',')\n",
    "# summarize the number of unique values in each column\n",
    "for i in range(data.shape[1]):\n",
    "    print(i, len(unique(data[:, i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c421d450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     238\n",
      "1     297\n",
      "2     927\n",
      "3     933\n",
      "4     179\n",
      "5     375\n",
      "6     820\n",
      "7     618\n",
      "8     561\n",
      "9      57\n",
      "10    577\n",
      "11     59\n",
      "12     73\n",
      "13    107\n",
      "14     53\n",
      "15     91\n",
      "16    893\n",
      "17    810\n",
      "18    170\n",
      "19     53\n",
      "20     68\n",
      "21      9\n",
      "22      1\n",
      "23     92\n",
      "24      9\n",
      "25      8\n",
      "26      9\n",
      "27    308\n",
      "28    447\n",
      "29    392\n",
      "30    107\n",
      "31     42\n",
      "32      4\n",
      "33     45\n",
      "34    141\n",
      "35    110\n",
      "36      3\n",
      "37    758\n",
      "38      9\n",
      "39      9\n",
      "40    388\n",
      "41    220\n",
      "42    644\n",
      "43    649\n",
      "44    499\n",
      "45      2\n",
      "46    937\n",
      "47    169\n",
      "48    286\n",
      "49      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# summarize the number of unique values for each column using numpy\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "df = read_csv('oil-spill.csv', header=None)\n",
    "# summarize the number of unique values in each column\n",
    "print(df.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3d8ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 50)\n",
      "Columns Name to be deleted/dropped:  [22]\n",
      "(937, 49)\n"
     ]
    }
   ],
   "source": [
    "# Delete Columns That Contain a Single Value\n",
    "#Variables or columns that have a single value should probably be removed from your dataset\n",
    "# delete columns with a single unique value\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "df = read_csv('oil-spill.csv', header=None)\n",
    "print(df.shape)\n",
    "# get number of unique values for each column\n",
    "counts = df.nunique()\n",
    "# record columns to delete\n",
    "todel = [i for i,v in enumerate(counts) if v == 1]\n",
    "print('Columns Name to be deleted/dropped: ',todel)\n",
    "# drop useless columns\n",
    "df.drop(todel,axis=1,inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71c82ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 238, 25.4%\n",
      "1, 297, 31.7%\n",
      "2, 927, 98.9%\n",
      "3, 933, 99.6%\n",
      "4, 179, 19.1%\n",
      "5, 375, 40.0%\n",
      "6, 820, 87.5%\n",
      "7, 618, 66.0%\n",
      "8, 561, 59.9%\n",
      "9, 57, 6.1%\n",
      "10, 577, 61.6%\n",
      "11, 59, 6.3%\n",
      "12, 73, 7.8%\n",
      "13, 107, 11.4%\n",
      "14, 53, 5.7%\n",
      "15, 91, 9.7%\n",
      "16, 893, 95.3%\n",
      "17, 810, 86.4%\n",
      "18, 170, 18.1%\n",
      "19, 53, 5.7%\n",
      "20, 68, 7.3%\n",
      "21, 9, 1.0%\n",
      "22, 1, 0.1%\n",
      "23, 92, 9.8%\n",
      "24, 9, 1.0%\n",
      "25, 8, 0.9%\n",
      "26, 9, 1.0%\n",
      "27, 308, 32.9%\n",
      "28, 447, 47.7%\n",
      "29, 392, 41.8%\n",
      "30, 107, 11.4%\n",
      "31, 42, 4.5%\n",
      "32, 4, 0.4%\n",
      "33, 45, 4.8%\n",
      "34, 141, 15.0%\n",
      "35, 110, 11.7%\n",
      "36, 3, 0.3%\n",
      "37, 758, 80.9%\n",
      "38, 9, 1.0%\n",
      "39, 9, 1.0%\n",
      "40, 388, 41.4%\n",
      "41, 220, 23.5%\n",
      "42, 644, 68.7%\n",
      "43, 649, 69.3%\n",
      "44, 499, 53.3%\n",
      "45, 2, 0.2%\n",
      "46, 937, 100.0%\n",
      "47, 169, 18.0%\n",
      "48, 286, 30.5%\n",
      "49, 2, 0.2%\n"
     ]
    }
   ],
   "source": [
    "#Consider Columns That Have Very Few Values\n",
    "# summarize the percentage of unique values for each column using numpy\n",
    "from numpy import loadtxt\n",
    "from numpy import unique\n",
    "\n",
    "# load the dataset\n",
    "data = loadtxt('oil-spill.csv', delimiter=',')\n",
    "\n",
    "# summarize the number of unique values in each column\n",
    "for i in range(data.shape[1]):\n",
    "    num = len(unique(data[:, i]))\n",
    "    percentage = float(num) / data.shape[0] * 100\n",
    "    print('%d, %d, %.1f%%' % (i, num, percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c4b9b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21, 9, 1.0%\n",
      "22, 1, 0.1%\n",
      "24, 9, 1.0%\n",
      "25, 8, 0.9%\n",
      "26, 9, 1.0%\n",
      "32, 4, 0.4%\n",
      "36, 3, 0.3%\n",
      "38, 9, 1.0%\n",
      "39, 9, 1.0%\n",
      "45, 2, 0.2%\n",
      "49, 2, 0.2%\n"
     ]
    }
   ],
   "source": [
    "# summarize the percentage of unique values for each column using numpy\n",
    "from numpy import loadtxt\n",
    "from numpy import unique\n",
    "# load the dataset\n",
    "data = loadtxt('oil-spill.csv', delimiter=',')\n",
    "\n",
    "# summarize the number of unique values in each column\n",
    "for i in range(data.shape[1]):\n",
    "    num = len(unique(data[:, i]))\n",
    "    percentage = float(num) / data.shape[0] * 100\n",
    "    if percentage < 1:\n",
    "        print('%d, %d, %.1f%%' % (i, num, percentage))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80683a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 50)\n",
      "[21, 22, 24, 25, 26, 32, 36, 38, 39, 45, 49]\n",
      "(937, 39)\n"
     ]
    }
   ],
   "source": [
    "# delete columns where number of unique values is less than 1% of the rows\n",
    "from pandas import read_csv\n",
    "\n",
    "# load the dataset\n",
    "df = read_csv('oil-spill.csv', header=None)\n",
    "print(df.shape)\n",
    "\n",
    "# get number of unique values for each column\n",
    "counts = df.nunique()\n",
    "\n",
    "# record columns to delete\n",
    "to_del = [i for i,v in enumerate(counts) if (float(v)/df.shape[0]*100) < 1]\n",
    "print(to_del)\n",
    "\n",
    "# drop useless columns\n",
    "df.drop(to_del, axis=1, inplace=True)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c3e65ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 49) (937,)\n",
      "(937, 48)\n"
     ]
    }
   ],
   "source": [
    "#Remove Columns That Have A Low Variance\n",
    "# example of applying the variance threshold for feature selection\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# load the dataset\n",
    "df = read_csv('oil-spill.csv', header=None)\n",
    "# split data into inputs and outputs\n",
    "data = df.values\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "# define the transform\n",
    "transform = VarianceThreshold()\n",
    "# transform the input data\n",
    "X_sel = transform.fit_transform(X)\n",
    "print(X_sel.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7cf8353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 49) (937,)\n",
      ">Threshold=0.00, Features=48\n",
      ">Threshold=0.05, Features=37\n",
      ">Threshold=0.10, Features=36\n",
      ">Threshold=0.15, Features=35\n",
      ">Threshold=0.20, Features=35\n",
      ">Threshold=0.25, Features=35\n",
      ">Threshold=0.30, Features=35\n",
      ">Threshold=0.35, Features=35\n",
      ">Threshold=0.40, Features=35\n",
      ">Threshold=0.45, Features=33\n",
      ">Threshold=0.50, Features=31\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore the effect of the variance thresholds on the number of selected features\n",
    "from numpy import arange\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from matplotlib import pyplot\n",
    "# load the dataset\n",
    "df = read_csv('oil-spill.csv', header=None)\n",
    "# split data into inputs and outputs\n",
    "data = df.values\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "# define thresholds to check\n",
    "thresholds = arange(0.0, 0.55, 0.05)\n",
    "\n",
    "# apply transform with each threshold\n",
    "results = list()\n",
    "for t in thresholds:\n",
    "    # define the transform\n",
    "    transform = VarianceThreshold(threshold=t)\n",
    "    # transform the input data\n",
    "    X_sel = transform.fit_transform(X)\n",
    "    # determine the number of input features\n",
    "    n_features = X_sel.shape[1]\n",
    "    print('>Threshold=%.2f, Features=%d' % (t, n_features))\n",
    "    # store the result\n",
    "    results.append(n_features)\n",
    "\n",
    "# plot the threshold vs the number of selected features\n",
    "pyplot.plot(thresholds, results)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08d9571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Rows That Contain Duplicate Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be6ece1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "       0    1    2    3               4\n",
      "34   4.9  3.1  1.5  0.1     Iris-setosa\n",
      "37   4.9  3.1  1.5  0.1     Iris-setosa\n",
      "142  5.8  2.7  5.1  1.9  Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "# locate rows of duplicate data\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "df = read_csv('iris.csv', header=None)\n",
    "# calculate duplicates\n",
    "dups = df.duplicated()\n",
    "# report if there are any duplicates\n",
    "print(dups.any())\n",
    "# list all duplicate rows\n",
    "print(df[dups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80e52046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n",
      "(147, 5)\n"
     ]
    }
   ],
   "source": [
    "#Delete Rows That Contain Duplicate Data\n",
    "# delete rows of duplicate data from the dataset\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "df = read_csv('iris.csv', header=None)\n",
    "print(df.shape)\n",
    "# delete duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de34410d",
   "metadata": {},
   "source": [
    "# Outlier Identification and Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461fd654",
   "metadata": {},
   "source": [
    "### Overview\n",
    "### 1. What are Outliers?\n",
    "### 2. Test Dataset\n",
    "### 3. Standard Deviation Method\n",
    "### 4. Interquartile Range Method\n",
    "### 5. Automatic Outlier Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "73f788d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are Outliers?\n",
    "#An outlier is an observation that is unlike the other observations. They are rare, distinct, or do not fit in some way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f24f43b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=50.049 stdv=4.994\n"
     ]
    }
   ],
   "source": [
    "#Test Dataset\n",
    "# generate gaussian data\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "# summarize\n",
    "print('mean=%.3f stdv=%.3f' % (mean(data), std(data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3308f",
   "metadata": {},
   "source": [
    "### Standard Deviation Method\n",
    "### If we know that the distribution of values in the sample is Gaussian or Gaussian-like, we can use the standard deviation of the sample as a cut-off for identifying outliers. The Gaussian distribution has the property that the standard deviation from the mean can be used to reliably summarize the percentage of values in the sample.\n",
    "\n",
    "###  1 Standard Deviation from the Mean: 68 percent.\n",
    "###  2 Standard Deviations from the Mean: 95 percent.\n",
    "###  3 Standard Deviations from the Mean: 99.7 percent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97ddf0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified outliers: 29\n",
      "Non-outlier observations: 9971\n"
     ]
    }
   ],
   "source": [
    "# identify outliers with standard deviation\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "\n",
    "# calculate summary statistics\n",
    "data_mean, data_std = mean(data), std(data)\n",
    "\n",
    "# define outliers\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "\n",
    "# identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print('Identified outliers: %d' % len(outliers))\n",
    "\n",
    "# remove outliers\n",
    "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "print('Non-outlier observations: %d' % len(outliers_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ddc102",
   "metadata": {},
   "source": [
    "### Interquartile Range Method\n",
    "### Not all data is normal or normal enough to treat it as being drawn from a Gaussian distribution. A good statistic for summarizing a non-Gaussian distribution sample of data is the Interquartile Range, or IQR for short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ced20063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles: 25th=46.685, 75th=53.359, IQR=6.674\n",
      "Identified outliers: 81\n",
      "Non-outlier observations: 9919\n"
     ]
    }
   ],
   "source": [
    "# identify outliers with interquartile range\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import percentile\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate univariate observations\n",
    "data = 5 * randn(10000) + 50\n",
    "# calculate interquartile range\n",
    "q25, q75 = percentile(data, 25), percentile(data, 75)\n",
    "iqr = q75 - q25\n",
    "print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 1.5\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "# identify outliers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print('Identified outliers: %d' % len(outliers))\n",
    "# remove outliers\n",
    "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "print('Non-outlier observations: %d' % len(outliers_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f5fbb0",
   "metadata": {},
   "source": [
    "### Automatic Outlier Detection\n",
    "### In machine learning, an approach to tackling the problem of outlier detection is one-class classification.\n",
    "### A one-class classifier aims at capturing characteristics of training instances, in order to be able to distinguish between them and potential outliers to appear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ccbcb666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "(339, 13) (167, 13) (339,) (167,)\n",
      "MAE: 3.417\n"
     ]
    }
   ],
   "source": [
    "# load and summarize the dataset\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# load the dataset\n",
    "df = read_csv('housing.csv', header=None)\n",
    "# retrieve the array\n",
    "data = df.values\n",
    "# split into input and output elements\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# summarize the shape of the dataset\n",
    "print(X.shape, y.shape)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize the shape of the train and test sets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bad32abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 13) (339,)\n",
      "(305, 13) (305,)\n",
      "MAE: 3.356\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on training dataset with outliers removed\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# load the dataset\n",
    "df = read_csv('housing.csv', header=None)\n",
    "# retrieve the array\n",
    "data = df.values\n",
    "# split into input and output elements\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize the shape of the training dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "# identify outliers in the training dataset\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "# select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "# summarize the shape of the updated training dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9e09c2",
   "metadata": {},
   "source": [
    "# How to Mark and Remove Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0cfd5",
   "metadata": {},
   "source": [
    "###  How to mark invalid or corrupt values as missing in your dataset.\n",
    "###  How to confirm that the presence of marked missing values causes problems for learning algorithms.\n",
    "###  How to remove rows with missing data from your dataset and evaluate a learning algorithm on the transformed dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc3293",
   "metadata": {},
   "source": [
    "### Overview\n",
    "### 1. Diabetes Dataset\n",
    "### 2. Mark Missing Values\n",
    "### 3. Missing Values Cause Problems\n",
    "### 4. Remove Rows With Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "744f607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1b843dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0           1           2           3           4           5  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
      "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
      "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
      "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
      "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
      "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
      "\n",
      "                6           7           8  \n",
      "count  768.000000  768.000000  768.000000  \n",
      "mean     0.471876   33.240885    0.348958  \n",
      "std      0.331329   11.760232    0.476951  \n",
      "min      0.078000   21.000000    0.000000  \n",
      "25%      0.243750   24.000000    0.000000  \n",
      "50%      0.372500   29.000000    0.000000  \n",
      "75%      0.626250   41.000000    1.000000  \n",
      "max      2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Mark Missing Values\n",
    "# load and summarize the dataset\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# summarize the dataset\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1cff2639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1   2   3    4     5      6   7  8\n",
      "0    6  148  72  35    0  33.6  0.627  50  1\n",
      "1    1   85  66  29    0  26.6  0.351  31  0\n",
      "2    8  183  64   0    0  23.3  0.672  32  1\n",
      "3    1   89  66  23   94  28.1  0.167  21  0\n",
      "4    0  137  40  35  168  43.1  2.288  33  1\n",
      "5    5  116  74   0    0  25.6  0.201  30  0\n",
      "6    3   78  50  32   88  31.0  0.248  26  1\n",
      "7   10  115   0   0    0  35.3  0.134  29  0\n",
      "8    2  197  70  45  543  30.5  0.158  53  1\n",
      "9    8  125  96   0    0   0.0  0.232  54  1\n",
      "10   4  110  92   0    0  37.6  0.191  30  0\n",
      "11  10  168  74   0    0  38.0  0.537  34  1\n",
      "12  10  139  80   0    0  27.1  1.441  57  0\n",
      "13   1  189  60  23  846  30.1  0.398  59  1\n",
      "14   5  166  72  19  175  25.8  0.587  51  1\n",
      "15   7  100   0   0    0  30.0  0.484  32  1\n",
      "16   0  118  84  47  230  45.8  0.551  31  1\n",
      "17   7  107  74   0    0  29.6  0.254  31  1\n",
      "18   1  103  30  38   83  43.3  0.183  33  0\n",
      "19   1  115  70  30   96  34.6  0.529  32  1\n"
     ]
    }
   ],
   "source": [
    "# load the dataset and review rows\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# summarize the first 20 rows of data\n",
    "print(dataset.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d36fb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# example of summarizing the number of missing values for each variable\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# count the number of missing values for each column\n",
    "num_missing = (dataset[[1,2,3,4,5]] == 0).sum()\n",
    "# report the results\n",
    "print(num_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "29a2cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# example of marking missing values with nan values\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# count the number of nan values in each column\n",
    "print(dataset.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c7e83845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0      1     2     3      4     5      6   7  8\n",
      "0    6  148.0  72.0  35.0    NaN  33.6  0.627  50  1\n",
      "1    1   85.0  66.0  29.0    NaN  26.6  0.351  31  0\n",
      "2    8  183.0  64.0   NaN    NaN  23.3  0.672  32  1\n",
      "3    1   89.0  66.0  23.0   94.0  28.1  0.167  21  0\n",
      "4    0  137.0  40.0  35.0  168.0  43.1  2.288  33  1\n",
      "5    5  116.0  74.0   NaN    NaN  25.6  0.201  30  0\n",
      "6    3   78.0  50.0  32.0   88.0  31.0  0.248  26  1\n",
      "7   10  115.0   NaN   NaN    NaN  35.3  0.134  29  0\n",
      "8    2  197.0  70.0  45.0  543.0  30.5  0.158  53  1\n",
      "9    8  125.0  96.0   NaN    NaN   NaN  0.232  54  1\n",
      "10   4  110.0  92.0   NaN    NaN  37.6  0.191  30  0\n",
      "11  10  168.0  74.0   NaN    NaN  38.0  0.537  34  1\n",
      "12  10  139.0  80.0   NaN    NaN  27.1  1.441  57  0\n",
      "13   1  189.0  60.0  23.0  846.0  30.1  0.398  59  1\n",
      "14   5  166.0  72.0  19.0  175.0  25.8  0.587  51  1\n",
      "15   7  100.0   NaN   NaN    NaN  30.0  0.484  32  1\n",
      "16   0  118.0  84.0  47.0  230.0  45.8  0.551  31  1\n",
      "17   7  107.0  74.0   NaN    NaN  29.6  0.254  31  1\n",
      "18   1  103.0  30.0  38.0   83.0  43.3  0.183  33  0\n",
      "19   1  115.0  70.0  30.0   96.0  34.6  0.529  32  1\n"
     ]
    }
   ],
   "source": [
    "# example of review data with missing values marked with a nan\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# summarize the first 20 rows of data\n",
    "print(dataset.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6aa585dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\inkri\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\inkri\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 550, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\inkri\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\inkri\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\inkri\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\inkri\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16772/2720192259.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m     cv_results = cross_validate(\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m     \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;31m# For callabe scoring, the return type is only know after calling. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    365\u001b[0m                 \u001b[1;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             )\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\inkri\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\inkri\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 550, in fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\inkri\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\inkri\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\inkri\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\inkri\\.conda\\envs\\projects\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLinearDiscriminantAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "#Missing Values Cause Problems\n",
    "# example where missing values cause errors\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:,0:8]\n",
    "y = values[:,8]\n",
    "# define the model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define the model evaluation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# evaluate the model\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "# report the mean performance\n",
    "print('Accuracy: %.3f' % result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e0082eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "#Remove Rows With Missing Values\n",
    "# example of removing rows that contain missing values\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# summarize the shape of the raw data\n",
    "print(dataset.shape)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# drop rows with missing values\n",
    "dataset.dropna(inplace=True)\n",
    "# summarize the shape of the data with missing rows removed\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba346de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.781\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on data after rows with missing data are removed\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# drop rows with missing values\n",
    "dataset.dropna(inplace=True)\n",
    "# split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:,0:8]\n",
    "y = values[:,8]\n",
    "# define the model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define the model evaluation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# evaluate the model\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "# report the mean performance\n",
    "print('Accuracy: %.3f' % result.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d9ff98",
   "metadata": {},
   "source": [
    "# How to Use Statistical Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7575c1f0",
   "metadata": {},
   "source": [
    "###  Missing values must be marked with NaN values and can be replaced with statistical measures to calculate the column of values.\n",
    "###  How to load a CSV file with missing values and mark the missing values with NaN values and report the number and percentage of missing values for each column.\n",
    "###  How to impute missing values with statistics as a data preparation method when evaluating models and when fitting a final model to make predictions on new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cd2ae2",
   "metadata": {},
   "source": [
    "### Overview\n",
    "### 1. Statistical Imputation\n",
    "### 2. Horse Colic Dataset\n",
    "### 3. Statistical Imputation With SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be4d6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Imputation\n",
    "#  The column mean value.\n",
    "#  The column median value.\n",
    "#  The column mode value.\n",
    "#  A constant value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c67eb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1        2     3      4     5    6    7    8    9   ...    18    19  \\\n",
      "0  2.0   1   530101  38.5   66.0  28.0  3.0  3.0  NaN  2.0  ...  45.0   8.4   \n",
      "1  1.0   1   534817  39.2   88.0  20.0  NaN  NaN  4.0  1.0  ...  50.0  85.0   \n",
      "2  2.0   1   530334  38.3   40.0  24.0  1.0  1.0  3.0  1.0  ...  33.0   6.7   \n",
      "3  1.0   9  5290409  39.1  164.0  84.0  4.0  1.0  6.0  2.0  ...  48.0   7.2   \n",
      "4  2.0   1   530255  37.3  104.0  35.0  NaN  NaN  6.0  2.0  ...  74.0   7.4   \n",
      "\n",
      "    20   21   22  23     24  25  26  27  \n",
      "0  NaN  NaN  2.0   2  11300   0   0   2  \n",
      "1  2.0  2.0  3.0   2   2208   0   0   2  \n",
      "2  NaN  NaN  1.0   2      0   0   0   1  \n",
      "3  3.0  5.3  2.0   1   2208   0   0   1  \n",
      "4  NaN  NaN  2.0   2   4300   0   0   2  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "> 0, Missing: 1 (0.3%)\n",
      "> 1, Missing: 0 (0.0%)\n",
      "> 2, Missing: 0 (0.0%)\n",
      "> 3, Missing: 60 (20.0%)\n",
      "> 4, Missing: 24 (8.0%)\n",
      "> 5, Missing: 58 (19.3%)\n",
      "> 6, Missing: 56 (18.7%)\n",
      "> 7, Missing: 69 (23.0%)\n",
      "> 8, Missing: 47 (15.7%)\n",
      "> 9, Missing: 32 (10.7%)\n",
      "> 10, Missing: 55 (18.3%)\n",
      "> 11, Missing: 44 (14.7%)\n",
      "> 12, Missing: 56 (18.7%)\n",
      "> 13, Missing: 104 (34.7%)\n",
      "> 14, Missing: 106 (35.3%)\n",
      "> 15, Missing: 247 (82.3%)\n",
      "> 16, Missing: 102 (34.0%)\n",
      "> 17, Missing: 118 (39.3%)\n",
      "> 18, Missing: 29 (9.7%)\n",
      "> 19, Missing: 33 (11.0%)\n",
      "> 20, Missing: 165 (55.0%)\n",
      "> 21, Missing: 198 (66.0%)\n",
      "> 22, Missing: 1 (0.3%)\n",
      "> 23, Missing: 0 (0.0%)\n",
      "> 24, Missing: 0 (0.0%)\n",
      "> 25, Missing: 0 (0.0%)\n",
      "> 26, Missing: 0 (0.0%)\n",
      "> 27, Missing: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# summarize the horse colic dataset\n",
    "from pandas import read_csv\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# summarize the first few rows\n",
    "print(dataframe.head())\n",
    "# summarize the number of rows with missing values for each column\n",
    "for i in range(dataframe.shape[1]):\n",
    "    # count number of rows with missing values\n",
    "    n_miss = dataframe[[i]].isnull().sum()\n",
    "    perc = n_miss / dataframe.shape[0] * 100\n",
    "    print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b15b800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 1605\n",
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "#Statistical Imputation With SimpleImputer\n",
    "# statistical imputation transform for the horse colic dataset\n",
    "from numpy import isnan\n",
    "from pandas import read_csv\n",
    "from sklearn.impute import SimpleImputer\n",
    "#load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "# summarize total missing\n",
    "print('Missing: %d' % sum(isnan(X).flatten()))\n",
    "# define imputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "# fit on the dataset\n",
    "imputer.fit(X)\n",
    "# transform the dataset\n",
    "Xtrans = imputer.transform(X)\n",
    "# summarize total missing\n",
    "print('Missing: %d' % sum(isnan(Xtrans).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "34984552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.872 (0.047)\n"
     ]
    }
   ],
   "source": [
    "#SimpleImputer and Model Evaluation\n",
    "# evaluate mean imputation and random forest for the horse colic dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "# define modeling pipeline\n",
    "model = RandomForestClassifier()\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])\n",
    "# define model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "966fecc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">mean 0.860 (0.058)\n",
      ">median 0.870 (0.062)\n",
      ">most_frequent 0.870 (0.053)\n",
      ">constant 0.882 (0.048)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparing Different Imputed Statistics\n",
    "# compare statistical imputation strategies for the horse colic dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "# evaluate each strategy on the dataset\n",
    "results = list()\n",
    "strategies = ['mean', 'median', 'most_frequent', 'constant']\n",
    "for s in strategies:\n",
    "    # create the modeling pipeline\n",
    "    pipeline = Pipeline(steps=[('i', SimpleImputer(strategy=s)), ('m',RandomForestClassifier())])\n",
    "    # evaluate the model\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # store results\n",
    "    results.append(scores)\n",
    "    print('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n",
    "    \n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=strategies, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "59ca0b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 2\n"
     ]
    }
   ],
   "source": [
    "#SimpleImputer Transform When Making a Prediction\n",
    "# constant imputation strategy and prediction for the horse colic dataset\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "\n",
    "# create the modeling pipeline\n",
    "pipeline = Pipeline(steps=[('i', SimpleImputer(strategy='constant')), ('m',RandomForestClassifier())])\n",
    "\n",
    "# fit the model\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# define new data\n",
    "row = [2, 1, 530101, 38.50, 66, 28, 3, 3, nan, 2, 5, 4, 4, nan, nan, nan, 3, 5, 45.00,8.40, nan, nan, 2, 11300, 00000, 00000, 2]\n",
    "\n",
    "# make a prediction\n",
    "yhat = pipeline.predict([row])\n",
    "\n",
    "# summarize prediction\n",
    "print('Predicted Class: %d' % yhat[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfae093",
   "metadata": {},
   "source": [
    "# How to Use KNN Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceeefc6",
   "metadata": {},
   "source": [
    "###  Missing values must be marked with NaN values and can be replaced with nearest neighbor estimated values.\n",
    "###  How to load a CSV file with missing values and mark the missing values with NaN values and report the number and percentage of missing values for each column.\n",
    "###  How to impute missing values with nearest neighbor models as a data preparation method when evaluating models and when fitting a final model to make predictions on new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7784819",
   "metadata": {},
   "source": [
    "### Overview\n",
    "### 1. k-Nearest Neighbor Imputation\n",
    "### 2. Horse Colic Dataset\n",
    "### 3. Nearest Neighbor Imputation With KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5180ce83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1        2     3      4     5    6    7    8    9   ...    18    19  \\\n",
      "0  2.0   1   530101  38.5   66.0  28.0  3.0  3.0  NaN  2.0  ...  45.0   8.4   \n",
      "1  1.0   1   534817  39.2   88.0  20.0  NaN  NaN  4.0  1.0  ...  50.0  85.0   \n",
      "2  2.0   1   530334  38.3   40.0  24.0  1.0  1.0  3.0  1.0  ...  33.0   6.7   \n",
      "3  1.0   9  5290409  39.1  164.0  84.0  4.0  1.0  6.0  2.0  ...  48.0   7.2   \n",
      "4  2.0   1   530255  37.3  104.0  35.0  NaN  NaN  6.0  2.0  ...  74.0   7.4   \n",
      "\n",
      "    20   21   22  23     24  25  26  27  \n",
      "0  NaN  NaN  2.0   2  11300   0   0   2  \n",
      "1  2.0  2.0  3.0   2   2208   0   0   2  \n",
      "2  NaN  NaN  1.0   2      0   0   0   1  \n",
      "3  3.0  5.3  2.0   1   2208   0   0   1  \n",
      "4  NaN  NaN  2.0   2   4300   0   0   2  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "> 0, Missing: 1 (0.3%)\n",
      "> 1, Missing: 0 (0.0%)\n",
      "> 2, Missing: 0 (0.0%)\n",
      "> 3, Missing: 60 (20.0%)\n",
      "> 4, Missing: 24 (8.0%)\n",
      "> 5, Missing: 58 (19.3%)\n",
      "> 6, Missing: 56 (18.7%)\n",
      "> 7, Missing: 69 (23.0%)\n",
      "> 8, Missing: 47 (15.7%)\n",
      "> 9, Missing: 32 (10.7%)\n",
      "> 10, Missing: 55 (18.3%)\n",
      "> 11, Missing: 44 (14.7%)\n",
      "> 12, Missing: 56 (18.7%)\n",
      "> 13, Missing: 104 (34.7%)\n",
      "> 14, Missing: 106 (35.3%)\n",
      "> 15, Missing: 247 (82.3%)\n",
      "> 16, Missing: 102 (34.0%)\n",
      "> 17, Missing: 118 (39.3%)\n",
      "> 18, Missing: 29 (9.7%)\n",
      "> 19, Missing: 33 (11.0%)\n",
      "> 20, Missing: 165 (55.0%)\n",
      "> 21, Missing: 198 (66.0%)\n",
      "> 22, Missing: 1 (0.3%)\n",
      "> 23, Missing: 0 (0.0%)\n",
      "> 24, Missing: 0 (0.0%)\n",
      "> 25, Missing: 0 (0.0%)\n",
      "> 26, Missing: 0 (0.0%)\n",
      "> 27, Missing: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# summarize the horse colic dataset\n",
    "from pandas import read_csv\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# summarize the first few rows\n",
    "print(dataframe.head())\n",
    "# summarize the number of rows with missing values for each column\n",
    "for i in range(dataframe.shape[1]):\n",
    "    # count number of rows with missing values\n",
    "    n_miss = dataframe[[i]].isnull().sum()\n",
    "    perc = n_miss / dataframe.shape[0] * 100\n",
    "    print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ce2024b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 1605\n",
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "#Nearest Neighbor Imputation with KNNImputer\n",
    "# knn imputation transform for the horse colic dataset\n",
    "from numpy import isnan\n",
    "from pandas import read_csv\n",
    "from sklearn.impute import KNNImputer\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "# summarize total missing\n",
    "print('Missing: %d' % sum(isnan(X).flatten()))\n",
    "# define imputer\n",
    "imputer = KNNImputer()\n",
    "# fit on the dataset\n",
    "imputer.fit(X)\n",
    "# transform the dataset\n",
    "Xtrans = imputer.transform(X)\n",
    "# summarize total missing\n",
    "print('Missing: %d' % sum(isnan(Xtrans).flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d871c93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.860 (0.050)\n"
     ]
    }
   ],
   "source": [
    "#KNNImputer and Model Evaluation\n",
    "# evaluate knn imputation and random forest for the horse colic dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "# define modeling pipeline\n",
    "model = RandomForestClassifier()\n",
    "imputer = KNNImputer()\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])\n",
    "# define model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "991c31ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.864 (0.051)\n",
      ">3 0.867 (0.055)\n",
      ">5 0.856 (0.059)\n",
      ">7 0.863 (0.055)\n",
      ">9 0.861 (0.058)\n",
      ">15 0.866 (0.055)\n",
      ">18 0.862 (0.052)\n",
      ">21 0.859 (0.061)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#KNNImputer and Different Number of Neighbors\n",
    "# compare knn imputation strategies for the horse colic dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "# evaluate each strategy on the dataset\n",
    "results = list()\n",
    "strategies = [str(i) for i in [1,3,5,7,9,15,18,21]]\n",
    "for s in strategies:\n",
    "    # create the modeling pipeline\n",
    "    pipeline = Pipeline(steps=[('i', KNNImputer(n_neighbors=int(s))), ('m',RandomForestClassifier())])\n",
    "    # evaluate the model\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # store results\n",
    "    results.append(scores)\n",
    "    print('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=strategies, showmeans=True)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7d413b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 2\n"
     ]
    }
   ],
   "source": [
    "#KNNImputer Transform When Making a Prediction\n",
    "# knn imputation strategy and prediction for the horse colic dataset\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "\n",
    "# create the modeling pipeline\n",
    "pipeline = Pipeline(steps=[('i', KNNImputer(n_neighbors=21)), ('m',RandomForestClassifier())])\n",
    "\n",
    "# fit the model\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# define new data\n",
    "row = [2, 1, 530101, 38.50, 66, 28, 3, 3, nan, 2, 5, 4, 4, nan, nan, nan, 3, 5, 45.00,8.40, nan, nan, 2, 11300, 00000, 00000, 2]\n",
    "\n",
    "# make a prediction\n",
    "yhat = pipeline.predict([row])\n",
    "# summarize prediction\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b594613",
   "metadata": {},
   "source": [
    "# How to Use Iterative Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37123f4",
   "metadata": {},
   "source": [
    "###  Missing values must be marked with NaN values and can be replaced with iteratively estimated values.\n",
    "###  How to load a CSV value with missing values and mark the missing values with NaN values and report the number and percentage of missing values for each column.\n",
    "###  How to impute missing values with iterative models as a data preparation method when evaluating models and when fitting a final model to make predictions on new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df6c020",
   "metadata": {},
   "source": [
    "### Overview\n",
    "### 1. Iterative Imputation\n",
    "### 2. Horse Colic Dataset\n",
    "### 3. Iterative Imputation With IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cbeadd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1        2     3      4     5    6    7    8    9   ...    18    19  \\\n",
      "0  2.0   1   530101  38.5   66.0  28.0  3.0  3.0  NaN  2.0  ...  45.0   8.4   \n",
      "1  1.0   1   534817  39.2   88.0  20.0  NaN  NaN  4.0  1.0  ...  50.0  85.0   \n",
      "2  2.0   1   530334  38.3   40.0  24.0  1.0  1.0  3.0  1.0  ...  33.0   6.7   \n",
      "3  1.0   9  5290409  39.1  164.0  84.0  4.0  1.0  6.0  2.0  ...  48.0   7.2   \n",
      "4  2.0   1   530255  37.3  104.0  35.0  NaN  NaN  6.0  2.0  ...  74.0   7.4   \n",
      "\n",
      "    20   21   22  23     24  25  26  27  \n",
      "0  NaN  NaN  2.0   2  11300   0   0   2  \n",
      "1  2.0  2.0  3.0   2   2208   0   0   2  \n",
      "2  NaN  NaN  1.0   2      0   0   0   1  \n",
      "3  3.0  5.3  2.0   1   2208   0   0   1  \n",
      "4  NaN  NaN  2.0   2   4300   0   0   2  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "> 0, Missing: 1 (0.3%)\n",
      "> 1, Missing: 0 (0.0%)\n",
      "> 2, Missing: 0 (0.0%)\n",
      "> 3, Missing: 60 (20.0%)\n",
      "> 4, Missing: 24 (8.0%)\n",
      "> 5, Missing: 58 (19.3%)\n",
      "> 6, Missing: 56 (18.7%)\n",
      "> 7, Missing: 69 (23.0%)\n",
      "> 8, Missing: 47 (15.7%)\n",
      "> 9, Missing: 32 (10.7%)\n",
      "> 10, Missing: 55 (18.3%)\n",
      "> 11, Missing: 44 (14.7%)\n",
      "> 12, Missing: 56 (18.7%)\n",
      "> 13, Missing: 104 (34.7%)\n",
      "> 14, Missing: 106 (35.3%)\n",
      "> 15, Missing: 247 (82.3%)\n",
      "> 16, Missing: 102 (34.0%)\n",
      "> 17, Missing: 118 (39.3%)\n",
      "> 18, Missing: 29 (9.7%)\n",
      "> 19, Missing: 33 (11.0%)\n",
      "> 20, Missing: 165 (55.0%)\n",
      "> 21, Missing: 198 (66.0%)\n",
      "> 22, Missing: 1 (0.3%)\n",
      "> 23, Missing: 0 (0.0%)\n",
      "> 24, Missing: 0 (0.0%)\n",
      "> 25, Missing: 0 (0.0%)\n",
      "> 26, Missing: 0 (0.0%)\n",
      "> 27, Missing: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# summarize the horse colic dataset\n",
    "from pandas import read_csv\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# summarize the first few rows\n",
    "print(dataframe.head())\n",
    "# summarize the number of rows with missing values for each column\n",
    "for i in range(dataframe.shape[1]):\n",
    "    # count number of rows with missing values\n",
    "    n_miss = dataframe[[i]].isnull().sum()\n",
    "    perc = n_miss / dataframe.shape[0] * 100\n",
    "    print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8047a016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 1605\n",
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "#Iterative Imputation With IterativeImputer\n",
    "# iterative imputation transform for the horse colic dataset\n",
    "from numpy import isnan\n",
    "from pandas import read_csv\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "# summarize total missing\n",
    "print('Missing: %d' % sum(isnan(X).flatten()))\n",
    "# define imputer\n",
    "imputer = IterativeImputer()\n",
    "# fit on the dataset\n",
    "imputer.fit(X)\n",
    "# transform the dataset\n",
    "Xtrans = imputer.transform(X)\n",
    "# summarize total missing\n",
    "print('Missing: %d' % sum(isnan(Xtrans).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "73abb8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.867 (0.052)\n"
     ]
    }
   ],
   "source": [
    "#IterativeImputer and Model Evaluation\n",
    "# evaluate iterative imputation and random forest for the horse colic dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "# define modeling pipeline\n",
    "model = RandomForestClassifier()\n",
    "imputer = IterativeImputer()\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])\n",
    "# define model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "81ef3430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">ascending 0.864 (0.052)\n",
      ">descending 0.867 (0.054)\n",
      ">roman 0.869 (0.052)\n",
      ">arabic 0.872 (0.054)\n",
      ">random 0.876 (0.047)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#IterativeImputer and Different Imputation Order\n",
    "# compare iterative imputation strategies for the horse colic dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "# evaluate each strategy on the dataset\n",
    "results = list()\n",
    "strategies = ['ascending', 'descending', 'roman', 'arabic', 'random']\n",
    "for s in strategies:\n",
    "    # create the modeling pipeline\n",
    "    pipeline = Pipeline(steps=[('i', IterativeImputer(imputation_order=s)), ('m',RandomForestClassifier())])\n",
    "    # evaluate the model\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # store results\n",
    "    results.append(scores)\n",
    "    print('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=strategies, showmeans=True)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d2e9f3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.874 (0.050)\n",
      ">2 0.877 (0.052)\n",
      ">3 0.880 (0.053)\n",
      ">4 0.867 (0.055)\n",
      ">5 0.870 (0.048)\n",
      ">6 0.870 (0.054)\n",
      ">7 0.870 (0.052)\n",
      ">8 0.870 (0.052)\n",
      ">9 0.870 (0.050)\n",
      ">10 0.870 (0.054)\n",
      ">11 0.872 (0.055)\n",
      ">12 0.872 (0.054)\n",
      ">13 0.870 (0.054)\n",
      ">14 0.873 (0.047)\n",
      ">15 0.871 (0.046)\n",
      ">16 0.870 (0.057)\n",
      ">17 0.871 (0.049)\n",
      ">18 0.871 (0.054)\n",
      ">19 0.872 (0.054)\n",
      ">20 0.873 (0.057)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#IterativeImputer and Different Number of Iterations\n",
    "# compare iterative imputation number of iterations for the horse colic dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "# evaluate each strategy on the dataset\n",
    "results = list()\n",
    "strategies = [str(i) for i in range(1, 21)]\n",
    "for s in strategies:\n",
    "    # create the modeling pipeline\n",
    "    pipeline = Pipeline(steps=[('i', IterativeImputer(max_iter=int(s))), ('m',RandomForestClassifier())])\n",
    "    # evaluate the model\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # store results\n",
    "    results.append(scores)\n",
    "    print('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=strategies, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d270fbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 2\n"
     ]
    }
   ],
   "source": [
    "#IterativeImputer Transform When Making a Prediction\n",
    "# iterative imputation strategy and prediction for the horse colic dataset\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# load dataset\n",
    "dataframe = read_csv('horse-colic.csv', header=None, na_values='?')\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "# create the modeling pipeline\n",
    "pipeline = Pipeline(steps=[('i', IterativeImputer()), ('m', RandomForestClassifier())])\n",
    "# fit the model\n",
    "pipeline.fit(X, y)\n",
    "# define new data\n",
    "row = [2, 1, 530101, 38.50, 66, 28, 3, 3, nan, 2, 5, 4, 4, nan, nan, nan, 3, 5, 45.00,\n",
    "8.40, nan, nan, 2, 11300, 00000, 00000, 2]\n",
    "# make a prediction\n",
    "yhat = pipeline.predict([row])\n",
    "# summarize prediction\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d665c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
